# Задача: научить систему автоматически извлекать ключевые сущности из пользовательских поисковых запросов.

## Технический стек решения для модели NER (Named Entity Recognition)
- Язык программирования: Python - основной язык разработки
- Машинное обучение/Глубокое обучение: PyTorch, Transformers (Hugging Face), Token Classification 
- Обработка данных: Pandas, NumPy 
- NLP и предобработка текста: Transformers Tokenizer, AST, RE (Regular Expressions)
- Метрики и оценка модели: Scikit-learn, Seqeval 
- Визуализация: Matplotlib, Seaborn
- Работа с данными: CSV/JSON, OS
- Утилиты: Random, Warnings

## Использованные предобученные модели

Мы пробовали разные модели, и лучшей моделью оказалась «bert-base-multilingual-cased».

**BERT-base Multilingual Cased**
- Тип: Предобученная языковая модель трансформеров
- Источник: Hugging Face Model Hub
- Разработчик: Google Research
- Назначение в проекте:
    - Использовалась в качестве базовой модели для тонкой настройки (fine-tuning)
    - Применялась для задачи распознавания именованных сущностей (NER)
    - Токенизатор модели использовался для предобработки текстовых данных
